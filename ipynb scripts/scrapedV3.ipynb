{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "import twitter\n",
    "import numpy as np\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading Keys\n",
    "api_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath('__file__'))))))\n",
    "data = json.load(open(os.path.join(api_dir, \"api_keys.json\")))\n",
    "\n",
    "# Setting Keys\n",
    "consumer_key = data['twitter_consumer_key']\n",
    "consumer_secret = data['twitter_consumer_secret']\n",
    "access_token = data['twitter_access_token']\n",
    "access_token_secret = data['twitter_access_token_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up Auth\n",
    "api = twitter.Api(consumer_key=consumer_key,\n",
    "                  consumer_secret=consumer_secret,\n",
    "                  access_token_key=access_token,\n",
    "                  access_token_secret=access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tweet Gather function\n",
    "def tweetGrab(city, city_dict, start_time):\n",
    "\n",
    "    # Call to API - each new call should return new tweets and count against rate-limit\n",
    "    tweets = api.GetSearch(geocode=[city_dict[f'{city}']['gps'][1],city_dict[f'{city}']['gps'][0], '20mi'],return_json=True)\n",
    "\n",
    "    # Loop to parse tweet and append data needed\n",
    "    for tweet in tweets['statuses']:\n",
    "\n",
    "        # If loop to ensure unique tweets\n",
    "        if tweet['text'] in city_dict[f'{city}']['data']['text']:\n",
    "            continue\n",
    "        else:        \n",
    "            # Appending important data\n",
    "            city_dict[f'{city}']['data']['text'].append(tweet['text'])\n",
    "            city_dict[f'{city}']['data']['bounding_box'].append(solveBox(tweet['place']['bounding_box']['coordinates']))\n",
    "            city_dict[f'{city}']['data']['user'].append(tweet['user']['screen_name'])\n",
    "            city_dict[f'{city}']['data']['created_at'].append(tweet['created_at'])\n",
    "            city_dict[f'{city}']['data']['followers_count'].append(tweet['user']['followers_count'])\n",
    "            city_dict[f'{city}']['data']['comp_sent'].append(analyzer.polarity_scores(tweet['text'])['compound'])\n",
    "\n",
    "            # Creating try loops for variable data that may or may not show up\n",
    "            try:\n",
    "                city_dict[f'{city}']['data']['coords'].append(tweet['coordinates']['coordinates'])\n",
    "            except:\n",
    "                city_dict[f'{city}']['data']['coords'].append(tweet['coordinates'])\n",
    "\n",
    "            try:\n",
    "                city_dict[f'{city}']['data']['profile_image_url'].append(tweet['user']['profile_image_url'])\n",
    "            except:\n",
    "                city_dict[f'{city}']['data']['profile_image_url'].append('None')\n",
    "\n",
    "            # Printing status of calls and current time\n",
    "            if (len(city_dict[f'{city}']['data']['text'])%5 == 0):\n",
    "                print(f'{city}: ' + str(len(city_dict[f'{city}']['data']['text'])) + ' --- %s seconds' % round(time.clock() - start_time,2))    \n",
    "\n",
    "    # Ending function\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating a rough coord based on bounding box\n",
    "def solveBox(bounding_box):\n",
    "    \n",
    "    # Creating temp dict and variable to return\n",
    "    coord_dict = {'lat': [], 'lon': []}\n",
    "    coord_return = []\n",
    "\n",
    "    # Small loop to append each coord to it's own list to sum\n",
    "    for coord in bounding_box[0]:\n",
    "        coord_dict['lat'].append(coord[1] + (np.random.rand() - np.random.rand()))\n",
    "        coord_dict['lon'].append(coord[0] + (np.random.rand() - np.random.rand()))\n",
    "\n",
    "    # Appending the sums to a return list\n",
    "    coord_return.append(round(np.mean(coord_dict['lon']),6))\n",
    "    coord_return.append(round(np.mean(coord_dict['lat']),6))\n",
    "\n",
    "    # Return list of coords\n",
    "    return(coord_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fills out the dictionary\n",
    "def fillDict():\n",
    "    \n",
    "    # City dictionary with static coords\n",
    "    city_dict = {\n",
    "        'Dallas': {'gps':[-96.796988, 32.776664], 'data':{}},\n",
    "        'St. Louis': {'gps':[-90.199404, 38.627003], 'data':{}},\n",
    "        'Los Angeles': {'gps':[-118.243685, 34.052234], 'data':{}},\n",
    "        'Atlanta': {'gps':[-84.387982, 33.748995], 'data':{}},\n",
    "        'Chicago': {'gps':[-87.629798, 41.878114], 'data':{}},\n",
    "        'Miami': {'gps':[-80.191790, 25.761680], 'data':{}},\n",
    "        'New York': {'gps':[-74.005973, 40.712775], 'data':{}},\n",
    "        'Kansas City': {'gps':[-94.578567, 39.099727], 'data':{}},\n",
    "        'Seattle': {'gps':[-122.332071, 47.606210], 'data':{}},\n",
    "        'Las Vegas': {'gps':[-115.139830, 36.169941], 'data':{}}\n",
    "        }\n",
    "\n",
    "    # Adding template to dictionary\n",
    "    for city in city_dict:\n",
    "\n",
    "        # Making lists for each entry\n",
    "        city_dict[f'{city}']['data']['text'] = [] \n",
    "        city_dict[f'{city}']['data']['coords'] = []\n",
    "        city_dict[f'{city}']['data']['bounding_box'] = []\n",
    "        city_dict[f'{city}']['data']['user'] = []\n",
    "        city_dict[f'{city}']['data']['profile_image_url'] = []\n",
    "        city_dict[f'{city}']['data']['created_at'] = []\n",
    "        city_dict[f'{city}']['data']['comp_sent'] = []\n",
    "        city_dict[f'{city}']['data']['followers_count'] = []\n",
    "\n",
    "    # Returning the dictionary\n",
    "    return(city_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to compress limit check\n",
    "def limit_check(check, city_dict, tweet_goal):\n",
    "    \n",
    "    # Creating empty check list\n",
    "    check_arr = []\n",
    "    \n",
    "    # Checking if any of the lists have reached the limit\n",
    "    if (check == 'first_to_goal'):\n",
    "        for city in city_dict:\n",
    "            if (len(city_dict[f'{city}']['data']['text'])>=tweet_goal):\n",
    "                check_arr.append(True)\n",
    "            else:\n",
    "                check_arr.append(False)\n",
    "                \n",
    "        # Setting limit based on 'not any' logic\n",
    "        limit = not any(check_arr)\n",
    "    \n",
    "    # Checking if all the lists have reached the limit\n",
    "    if (check == 'all_to_goal'):\n",
    "        for city in city_dict:\n",
    "            if (len(city_dict[f'{city}']['data']['text'])<tweet_goal):\n",
    "                check_arr.append(True)\n",
    "            else:\n",
    "                check_arr.append(False)   \n",
    "        \n",
    "        # Setting limit based on 'any' logic\n",
    "        limit = any(check_arr)\n",
    "    \n",
    "    # Returning a bool to check against for loop\n",
    "    return(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save output to a txt/json doc for easy read later\n",
    "def saveOutput(data, tweet_goal, start_time, limit_type):\n",
    "    with open('data.txt', 'w') as outfile:\n",
    "        json.dump(data, outfile, sort_keys = True, indent = 2)\n",
    "    with open(f'{limit_type} - {tweet_goal} Tweets - ' + str(round(time.clock()-start_time,2)) + f' Runtime - {start_time}.txt', 'w') as outfile:\n",
    "        json.dump(data, outfile, sort_keys = True, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print Final Output\n",
    "def printOutput(city_dict, start_time):\n",
    "    \n",
    "    # Starting printing format\n",
    "    print('-------------------------------------------')\n",
    "    \n",
    "    # Loop to print each list length\n",
    "    for city in city_dict:\n",
    "        print(f'{city}:' + str(len(city_dict[f'{city}']['data']['text'])))\n",
    "    \n",
    "    # Final Format Print with runtime\n",
    "    print('-------------------------------------------')\n",
    "    print(' --- %s Runtime' % round(time.clock() - start_time,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "def twitterize():\n",
    "    \n",
    "    # Setting up statics\n",
    "    tweet_goal = 20\n",
    "    limit_type = 'first_to_goal' # 'first_to_goal' or 'all_to_goal'\n",
    "    start_time = time.clock()\n",
    "    \n",
    "    # Finding the dict\n",
    "    city_dict = fillDict()\n",
    "\n",
    "    # Main loop - Checks what type of limit is set and runs until False is returned\n",
    "    while (limit_check(limit_type, city_dict, tweet_goal) == True):\n",
    "        \n",
    "        # Rotates cities - Causes a delay so new tweets can be fed to the API\n",
    "        for city in city_dict:\n",
    "            tweetGrab(city, city_dict, start_time)\n",
    "            time.sleep(6)\n",
    "\n",
    "    # Saving output to txt file\n",
    "    saveOutput(city_dict, tweet_goal, start_time, limit_type)\n",
    "    \n",
    "    # Printing runtime\n",
    "    printOutput(city_dict, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kansas City: 5 --- 170.44 seconds\n",
      "Dallas: 5 --- 189.71 seconds\n",
      "Chicago: 5 --- 277.51 seconds\n",
      "Kansas City: 10 --- 296.29 seconds\n",
      "Las Vegas: 5 --- 371.76 seconds\n",
      "Los Angeles: 5 --- 390.64 seconds\n",
      "Miami: 5 --- 409.46 seconds\n",
      "New York: 5 --- 415.78 seconds\n",
      "Seattle: 5 --- 428.29 seconds\n",
      "Dallas: 10 --- 440.77 seconds\n",
      "St. Louis: 5 --- 509.99 seconds\n",
      "Chicago: 10 --- 591.57 seconds\n",
      "Atlanta: 5 --- 711.05 seconds\n",
      "Dallas: 15 --- 755.28 seconds\n",
      "Los Angeles: 10 --- 767.91 seconds\n",
      "Miami: 10 --- 786.67 seconds\n",
      "New York: 10 --- 792.93 seconds\n",
      "Seattle: 10 --- 805.47 seconds\n",
      "Las Vegas: 10 --- 811.72 seconds\n",
      "Chicago: 15 --- 843.06 seconds\n",
      "Kansas City: 15 --- 861.89 seconds\n",
      "St. Louis: 10 --- 949.79 seconds\n",
      "Dallas: 20 --- 1006.12 seconds\n",
      "Miami: 15 --- 1037.72 seconds\n",
      "New York: 15 --- 1044.0 seconds\n",
      "Kansas City: 20 --- 1050.24 seconds\n",
      "-------------------------------------------\n",
      "Dallas:21\n",
      "St. Louis:10\n",
      "Los Angeles:14\n",
      "Atlanta:9\n",
      "Chicago:18\n",
      "Miami:15\n",
      "New York:15\n",
      "Kansas City:20\n",
      "Seattle:13\n",
      "Las Vegas:14\n",
      "-------------------------------------------\n",
      " --- 1068.76 Runtime\n"
     ]
    }
   ],
   "source": [
    "twitterize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
